FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535520000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464480000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=3 11 9 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (3, 5, 9.99999977648258210000e-003) (0, 0, 0.00000000000000000000e+000) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (11, 5, 9.99999977648258210000e-003) (0, 0, 0.00000000000000000000e+000) (9, 5, 9.99999977648258210000e-003) (9, 5, 9.99999977648258210000e-003) (0, 0, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, -1.48444799804687500000e+003) (1, -1.48444799804687500000e+003) (2, 2.03005969524383540000e-001) (0, 1.50000000000000000000e+003) (1, 1.50000000000000000000e+003) (2, -2.11030066013336180000e-001) (0, 1.50000000000000000000e+003) (1, 1.50000000000000000000e+003) (2, -1.43426299095153810000e-001) (0, 1.50000000000000000000e+003) (1, 1.50000000000000000000e+003) (2, -1.66240096092224120000e-001) (0, -1.36368798828125000000e+003) (1, -1.36368798828125000000e+003) (2, 4.30761545896530150000e-001) (0, -1.42028002929687500000e+003) (1, -1.42028002929687500000e+003) (2, 1.10381729900836940000e-001) (0, 1.46411999511718750000e+003) (1, 1.46411999511718750000e+003) (2, 7.46663734316825870000e-002) (0, -1.42028002929687500000e+003) (1, -1.42028002929687500000e+003) (2, 1.20962440967559810000e-001) (0, 1.50000000000000000000e+003) (1, 1.50000000000000000000e+003) (2, -5.02118133008480070000e-002) (0, -1.42028002929687500000e+003) (1, -1.42028002929687500000e+003) (2, 1.67228087782859800000e-001) (3, 2.24058523774147030000e-001) (4, 2.76933521032333370000e-001) (5, 7.82430171966552730000e-001) (6, 8.45162153244018550000e-001) (7, 2.02023267745971680000e-001) (8, -1.31754350662231450000e+000) (9, 4.20800983905792240000e-001) (10, -1.41522407531738280000e+000) (11, 1.66407203674316410000e+000) (12, -4.95965689420700070000e-001) (13, 6.02156043052673340000e-001) (3, 2.92649775743484500000e-001) (4, 2.21586853265762330000e-001) (5, 6.93788766860961910000e-001) (6, 7.85684466361999510000e-001) (7, 1.27066433429718020000e-001) (8, -1.28601264953613280000e+000) (9, 3.54217767715454100000e-001) (10, -1.27416563034057620000e+000) (11, 1.72526574134826660000e+000) (12, -5.57807683944702150000e-001) (13, 5.95429956912994380000e-001) (3, -1.20230615139007570000e+000) (4, 1.15560836791992190000e+001) (5, 5.66271018981933590000e+000) (6, 5.73047161102294920000e+000) (7, -1.22804975509643550000e+001) (8, -6.41952753067016600000e-001) (9, 2.46476993560791020000e+001) (10, -6.31326913833618160000e-001) (11, -2.60919761657714840000e+000) (12, -5.73630571365356450000e-001) (13, -1.66150927543640140000e-001) (3, 4.73983377218246460000e-001) (4, -5.62305115163326260000e-002) (5, -1.11759638786315920000e+000) (6, -1.13065195083618160000e+000) (7, 7.48389720916748050000e-001) (8, 2.37101817131042480000e+000) (9, -2.92131990194320680000e-001) (10, 2.36010503768920900000e+000) (11, -1.56316828727722170000e+000) (12, 1.51247692108154300000e+000) (13, 1.93405285477638240000e-001) (3, -1.58287256956100460000e-001) (4, 2.61374402046203610000e+000) (5, 5.75777816772460940000e+000) (6, 5.73131370544433590000e+000) (7, -1.23554000854492190000e+001) (8, -5.57382822036743160000e-001) (9, 2.46860485076904300000e+001) (10, -6.37570619583129880000e-001) (11, -2.47175312042236330000e+000) (12, -6.77475214004516600000e-001) (13, -1.74054980278015140000e-001) (3, 2.61447429656982420000e-001) (4, 2.32326343655586240000e-001) (5, 3.00982743501663210000e-001) (6, 3.53424578905105590000e-001) (7, -1.78728878498077390000e-001) (8, -3.71128976345062260000e-001) (9, 6.00159540772438050000e-002) (10, -2.45338514447212220000e-001) (11, 1.30047237873077390000e+000) (12, -7.19725862145423890000e-002) (13, 3.58421891927719120000e-001) (3, 4.10132944583892820000e-001) (4, 5.60253083705902100000e-001) (5, 5.32084167003631590000e-001) (6, 6.41044080257415770000e-002) (7, -3.79560023546218870000e-001) (8, 4.31784057617187500000e+000) (9, -5.21935510635375980000e+000) (10, 1.98583650588989260000e+000) (11, -1.07607543468475340000e+000) (12, 1.34385228157043460000e+000) (13, -8.39396845549345020000e-003) (3, -2.76738796234130860000e+001) (4, 2.88078079223632810000e+001) (5, 5.27577857971191410000e+001) (6, 3.33856048583984380000e+001) (7, -1.50098047256469730000e+001) (8, -4.69339561462402340000e+001) (9, 6.66084518432617190000e+001) (10, -4.70675239562988280000e+001) (11, 5.32631149291992190000e+001) (12, -2.90999202728271480000e+001) (13, -2.68095046281814580000e-001) (14, -4.31522041559219360000e-001) (15, -4.54471260309219360000e-001) (16, 1.00796866416931150000e+000) (17, 9.51756536960601810000e-002) (18, 1.04527926445007320000e+000) (19, -4.15084093809127810000e-001) (20, 5.16868412494659420000e-001) (21, 6.29723191261291500000e-001) (22, 1.59015897661447530000e-002) (14, 3.00679862499237060000e-001) (15, 3.22646439075469970000e-001) (16, 3.35266143083572390000e-001) (17, -6.63237497210502620000e-002) (18, 2.83540070056915280000e-001) (19, 3.52156966924667360000e-001) (20, 2.22650498151779170000e-001) (21, 7.44258284568786620000e-001) (22, 2.25017638877034190000e-003) 
